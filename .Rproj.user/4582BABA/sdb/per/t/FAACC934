{
    "contents" : "\n# This is the server logic for a Shiny web application.\n# You can find out more about building applications with Shiny here:\n#\n# http://shiny.rstudio.com\n#\n\nlibrary(shiny)\nlibrary(tm)      # Text Minning Library    \nlibrary(stringr) # Support to basic file summary\nlibrary(RWeka)   # Support to n-gram processes\nlibrary(stringi)\nlibrary(slam)\nlibrary(dplyr)\nlibrary(data.table)\n\ninputText <<- \"OMG\"\nresultText <<- NULL\ntriGramResults <<- NULL\nbinGramResults <<- NULL\nuniGramResults <<- NULL\nprocessTime <<- NULL\n\npredictSentence <-function(sentence = \"hello world\"){\n  inputText <<- sentence\n  start.time <- Sys.time()\n  corST <- Corpus(VectorSource(inputText), readerControl=list(reader=readPlain, language=\"en_US\", load=TRUE))\n  corST <- cleanData(corST,cleanType = \"test\")\n  t <- tail(strsplit(corST[[1]]$content, \" \")[[1]],3)\n  n <- length(t)\n  triPred = NULL; binPred = NULL; uniPred = NULL\n  if(n >= 3) {\n    tri <- paste(t[n-2], t[n-1], t[n]) \n    triPred <- predictWord(input=tri, readFromFolder = \"finaldata\",readPredix = \"quaFinal_\")\n  }\n  if(n >= 2) {\n    bin <- paste(t[n-1], t[n])\n    binPred <- predictWord(input=bin, readFromFolder = \"finaldata\",readPredix = \"triFinal_\")\n  }\n  if(n >= 1) {\n    uni <- paste(t[n])\n    uniPred <- predictWord(input=uni, readFromFolder = \"finaldata\",readPredix = \"binFinal_\")\n  }\n  \n  result <- c(triPred$predict[1],binPred$predict[1],uniPred$predict[1])\n  resultText <<- result[!is.na(result)][1]\n  triGramResults <<- triPred\n  binGramResults <<- binPred\n  uniGramResults <<- uniPred\n  processTime<<-(Sys.time() - start.time)\n}\n\n##--------------------\npredictWord <- function(input,readFromFolder, readPredix){\n  fstChar <- substr(input, 1, 1)\n  df <- data.table(read.table(file=paste0(readFromFolder,\"/\",readPredix,fstChar, \".txt\"),header = TRUE))\n  df$inputterm <- as.character(df$inputterm)\n  df$predict <- as.character(df$predict) \n  df$freq <- as.numeric(df$freq)\n  df[inputterm==input]\n}\n##--------------------\ncleanData <- function(x, cleanType = \"train\"){\n  #remove non Unicode characters\n  x <- tm_map(x, content_transformer(function(x) iconv(enc2utf8(x), sub = \"\")))\n  #remove non ASCII characters\n  x <- tm_map(x, content_transformer(function(x) iconv(x,from = \"latin1\", to=\"ASCII\", sub=\"\")))\n  #low case and remove Stopwords\n  x <- tm_map(x, content_transformer(tolower))\n  #x <- tm_map(x, removeWords, stopwords(\"english\"))\n  #remove special character but not .?;\"!() those will be a delimit signal when devided into ngram\n  x <- tm_map(x,content_transformer(function(x) stri_replace_all_regex(x, \"[^\\\\p{L}\\\\s[.?;!()\\\"]]+\",\"\")))\n  #convert .?;!() character to \" . \" delimiter\n  #x <- tm_map(x,content_transformer(function(x) stri_replace_all_regex(x, \"[[.,?;!()]]+\",\" . \")))\n  \n  x <- tm_map(x, removeNumbers)\n  #close when train open when run\n  if (cleanType ==\"test\") x <- tm_map(x, content_transformer(removePunctuation))\n  #x <- tm_map(x, removeWords, profWords) # Remove profane words\n  \n  x <- tm_map(x, stripWhitespace)\n  x\n}\n\nshinyServer(function(input, output) {\n  \n  #runmyapp <- reactive({predictSentence(input$iTextInput)})\n  \n  output$oInputText <- renderPrint({inputText})\n  #output$oResultText <- renderPrint({resultText})\n  #output$oProcessTime <- renderPrint({processTime})\n  #output$oTriGramResults <- renderPrint({triGramResults})\n  #output$oBinGramResults <- renderPrint({binGramResults})\n  #output$oUniGramResults <- renderPrint({uniGramResults})\n})\n",
    "created" : 1459674471815.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4287090024",
    "id" : "FAACC934",
    "lastKnownWriteTime" : 1459680935,
    "path" : "D:/Education/Data Science/CapstoneProject/SwiftKey_Project/server.R",
    "project_path" : "server.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_source"
}